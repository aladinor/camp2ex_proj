{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7829c0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/keeling/a/alfonso8/miniconda3/envs/camp2ex_proj/lib/python3.9/site-packages/dask/dataframe/backends.py:181: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/data/keeling/a/alfonso8/miniconda3/envs/camp2ex_proj/lib/python3.9/site-packages/dask/dataframe/backends.py:181: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/data/keeling/a/alfonso8/miniconda3/envs/camp2ex_proj/lib/python3.9/site-packages/dask/dataframe/backends.py:181: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import xarray as xr\n",
    "from dask import delayed, compute\n",
    "import itertools\n",
    "from pytmatrix import tmatrix_aux, refractive, tmatrix, radar\n",
    "from pymiecoated import Mie\n",
    "from scipy.constants import c\n",
    "from sqlalchemy.exc import OperationalError\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from re import split\n",
    "import matplotlib.dates as mdates\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client, progress\n",
    "import dask.dataframe as dd\n",
    "from dask import delayed, compute\n",
    "\n",
    "sys.path.insert(1, f\"{os.path.abspath(os.path.join(os.path.abspath(''), '../'))}\")\n",
    "from src.utils import get_pars_from_ini, make_dir\n",
    "\n",
    "location = split(', |_|-|!', os.popen('hostname').read())[0].replace(\"\\n\", \"\")\n",
    "path_data = get_pars_from_ini(file_name='loc')[location]['path_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eba175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdict = {'red': ((0., 1, 1),\n",
    "                 (0.05, 1, 1),\n",
    "                 (0.11, 0, 0),\n",
    "                 (0.66, 1, 1),\n",
    "                 (0.89, 1, 1),\n",
    "                 (1, 0.5, 0.5)),\n",
    "         'green': ((0., 1, 1),\n",
    "                   (0.05, 1, 1),\n",
    "                   (0.11, 0, 0),\n",
    "                   (0.375, 1, 1),\n",
    "                   (0.64, 1, 1),\n",
    "                   (0.91, 0, 0),\n",
    "                   (1, 0, 0)),\n",
    "         'blue': ((0., 1, 1),\n",
    "                  (0.05, 1, 1),\n",
    "                  (0.11, 1, 1),\n",
    "                  (0.34, 1, 1),\n",
    "                  (0.65, 0, 0),\n",
    "                  (1, 0, 0))}\n",
    "\n",
    "my_cmap = LinearSegmentedColormap('my_colormap', cdict, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bc2b86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(instrument='Lear', temp=2):\n",
    "    \"\"\"\n",
    "\n",
    "    :param instrument: aircraft\n",
    "    :param temp: temperature for filtering\n",
    "    :return: list of available dataframe in CAMP2ex\n",
    "    \"\"\"\n",
    "    if instrument == 'Lear':\n",
    "        ls_lear = glob.glob(f'{path_data}/data/LAWSON.PAUL/LEARJET/all/*.pkl')\n",
    "        ls_lear = [i for i in ls_lear if not i.split('/')[-1].startswith('Page0')]\n",
    "        ls_temp = glob.glob(f'{path_data}/data/LAWSON.PAUL/LEARJET/all/Page0*.pkl')[0]\n",
    "        ls_lear.append(ls_temp)\n",
    "        lear_df = [pd.read_pickle(i) for i in ls_lear]\n",
    "        _attrs = [i.attrs for i in lear_df[:-1]]\n",
    "        if temp:\n",
    "            lear_df = [pd.merge(i, lear_df[-1]['Temp'], right_index=True, left_index=True) for i in lear_df[:-1]]\n",
    "            lear_df = [i[i['Temp'] > temp] for i in lear_df]\n",
    "        for i, attrs in enumerate(_attrs):\n",
    "            lear_df[i].attrs = attrs\n",
    "        lear_dd = [dd.from_pandas(i, npartitions=1) for i in lear_df]\n",
    "        del lear_df\n",
    "        return lear_dd\n",
    "    elif instrument == 'P3B':\n",
    "        ls_p3 = glob.glob(f'{path_data}/data/LAWSON.PAUL/P3B/all/*.pkl')\n",
    "        p3_merged = glob.glob(f'{path_data}/data/01_SECOND.P3B_MRG/MERGE/all/*pkl')\n",
    "        p3_temp = pd.read_pickle(p3_merged[0])\n",
    "        p3_df = [pd.read_pickle(i) for i in ls_p3]\n",
    "        _attrs = [i.attrs for i in p3_df]\n",
    "        p3_df = [pd.merge(i, p3_temp[' Static_Air_Temp_YANG_MetNav'], left_index=True, right_index=True) for i in p3_df]\n",
    "        temp = 2\n",
    "        for i, df in enumerate(p3_df):\n",
    "            df.attrs = _attrs[i]\n",
    "            df.rename(columns={' Static_Air_Temp_YANG_MetNav': 'Temp'}, inplace=True)\n",
    "            if temp:\n",
    "                df = df[df['Temp'] >= temp]\n",
    "            p3_df[i] = df\n",
    "        p3_dd = [dd.from_pandas(i, npartitions=1) for i in p3_df]\n",
    "        del p3_df\n",
    "        return p3_dd\n",
    "    else:\n",
    "        raise TypeError(f\"{instrument} not available. Use Lear or P3B\")\n",
    "\n",
    "\n",
    "def change_cols(df):\n",
    "    bin_cent = df.attrs['bin_cent']\n",
    "    cols = df.columns\n",
    "    new_cols = {cols[i]: bin_cent[i] for i in range(len(cols))}\n",
    "    df = df.rename(columns=new_cols)\n",
    "    return df\n",
    "\n",
    "\n",
    "@delayed\n",
    "def change_cols(df):\n",
    "    bin_cent = df.attrs['bin_cent']\n",
    "    cols = df.columns\n",
    "    new_cols = {cols[i]: bin_cent[i] for i in range(len(cols))}\n",
    "    df = df.rename(columns=new_cols)\n",
    "    return df\n",
    "\n",
    "\n",
    "def filt_by_instrument(ls_df, hawk=False):\n",
    "    if not hawk:\n",
    "        ls_df = [i for i in ls_df if not i.attrs['instrument'].startswith('Hawk')]\n",
    "        return ls_df\n",
    "    else:\n",
    "        return ls_df\n",
    "\n",
    "\n",
    "def filt_by_cols(ls_df):\n",
    "    # if cols:\n",
    "    cols = [[j for j in i.columns if j.startswith('nsd')] for i in ls_df]\n",
    "    ls_df = [i[cols[j]] for j, i in enumerate(ls_df)]\n",
    "    ls_df = [change_cols(i) for i in ls_df]\n",
    "    return ls_df\n",
    "\n",
    "\n",
    "def get_intervals(ls_df):\n",
    "    cols = [[pd.Interval(j.attrs['sizes'][i], j.attrs['sizes'][i + 1]) for i in\n",
    "             range(len(j.attrs['sizes']) - 1)] for j in ls_df]\n",
    "    cols = [j + [pd.Interval(ls_df[i].attrs['sizes'][-1], list(ls_df[i].attrs['dsizes'].keys())[-1])]\n",
    "            for i, j in enumerate(cols)]\n",
    "    return cols\n",
    "\n",
    "\n",
    "def apply_wgt(df, ovr_upp, ovr_lower):\n",
    "    if (df['2DS10'] != 0) & (df['HVPS'] != 0):\n",
    "        df['2ds10_wgt'] = df['2DS10'] * df['2DS10'].index.values / (ovr_upp - ovr_lower)\n",
    "        df['hvps_wgt'] = df['HVPS'] * (df['HVPS'].index.values - ovr_lower) / (ovr_upp - ovr_lower)\n",
    "        df['nd_res'] = df[['2ds10_wgt', 'hvps_wgt']].dropna(how='all').sum(1)\n",
    "        return df['nd_res']\n",
    "    elif (df['2DS10'] == 0) & (df['HVPS'] != 0):\n",
    "        return df['HVPS']\n",
    "    elif (df['2DS10'] != 0) & (df['HVPS'] == 0):\n",
    "        return df['HVPS']\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def linear_wgt(df1, df2, ovr_upp=1200, ovr_lower=800, method='linear'):\n",
    "    \"\"\"\n",
    "\n",
    "    :param method: method to apply. linear applies Leroy et al. 2014. swal Applies Snesbitt method\n",
    "    :param df1: pandas series with the small diameter sizes (e.g. 2DS10)\n",
    "    :param df2: pandas series with the small diameter sizes (e.g. HVPS)\n",
    "    :param ovr_upp: upper limit for overlapping\n",
    "    :param ovr_lower: lower limit for overlapping\n",
    "    :return: pd series with a composite PSD\n",
    "    \"\"\"\n",
    "    df1.index = df1.attrs['2DS10']['intervals']\n",
    "    df2.index = df2.attrs['HVPS']['intervals']\n",
    "    cond1 = (df1.index.mid >= ovr_lower) & (df1.index.mid <= ovr_upp)\n",
    "    cond2 = (df2.index.mid >= ovr_lower) & (df2.index.mid <= ovr_upp)\n",
    "    _nd_uppr = df1[cond1]\n",
    "    _nd_lower = df2[cond2]\n",
    "\n",
    "    nd_overlap = pd.concat([_nd_uppr.reindex(np.arange(ovr_lower, ovr_upp, 5)),\n",
    "                            _nd_lower.reindex(np.arange(ovr_lower, ovr_upp, 5))], axis=1)\n",
    "    if method == 'linear':\n",
    "        nd_overlap['2ds10_wgt'] = nd_overlap['2DS10'] * (ovr_upp - nd_overlap['2DS10'].index.values) / \\\n",
    "                                  (ovr_upp - ovr_lower)\n",
    "        nd_overlap['hvps_wgt'] = nd_overlap['HVPS'] * (nd_overlap['HVPS'].index.values - ovr_lower) / \\\n",
    "                                 (ovr_upp - ovr_lower)\n",
    "        nd_overlap['nd_res'] = nd_overlap[['2ds10_wgt', 'hvps_wgt']].dropna(how='all').sum(1)\n",
    "        nd_overlap = nd_overlap.reindex(df1[cond1].index.mid)\n",
    "        nd_overlap.index = df1[cond1].index\n",
    "        res = pd.concat([df1[df1.index.mid <= ovr_lower], nd_overlap['nd_res'], df2[df2.index.mid >= ovr_upp]])\n",
    "        res.index = res.index.mid\n",
    "        return res\n",
    "\n",
    "    elif 'snal':\n",
    "        _sdd = nd_overlap.where(\n",
    "            (nd_overlap['2DS10'] != 0) & (nd_overlap['HVPS'] != 0) & (nd_overlap['2DS10'].notnull()) &\n",
    "            (nd_overlap['HVPS'] != 0).notnull()).dropna(how='any')\n",
    "        _sdd['2ds10_wgt'] = _sdd['2DS10'] * (ovr_upp - _sdd['2DS10'].index.values) / (ovr_upp - ovr_lower)\n",
    "        _sdd['hvps_wgt'] = _sdd['HVPS'] * (_sdd['HVPS'].index.values - ovr_lower) / (ovr_upp - ovr_lower)\n",
    "        _sdd['nd_res'] = _sdd[['2ds10_wgt', 'hvps_wgt']].sum(1)\n",
    "\n",
    "        _sdc = nd_overlap.where(((nd_overlap['2DS10'] == 0) | (nd_overlap['2DS10'].isnull())) &\n",
    "                                (nd_overlap['HVPS'] != 0)).dropna(how='all')['HVPS']\n",
    "        _sds = nd_overlap.where((nd_overlap['2DS10'] != 0) & ((nd_overlap['HVPS'] == 0) |\n",
    "                                                              (nd_overlap['HVPS'].isnull()))).dropna(how='all')['2DS10']\n",
    "        res = pd.concat([_sdd['nd_res'], _sdc, _sds]).sort_index()\n",
    "        res = res.reindex(df1[cond1].index.mid)\n",
    "        res.index = df1[cond1].index\n",
    "        res = pd.concat([df1[df1.index.mid <= ovr_lower], res, df2[df2.index.mid >= ovr_upp]])\n",
    "        res.index = res.index.mid\n",
    "        return res\n",
    "\n",
    "\n",
    "def vel(d):\n",
    "    return -0.1021 + 4.932 * d - 0.955 * d ** 2 + 0.07934 * d ** 3 - 0.0023626 * d ** 4\n",
    "\n",
    "\n",
    "def pds_parameters(nd):\n",
    "    \"\"\"\n",
    "    Compute the psd parameters\n",
    "    :param nd: partice size distribution in # L-1 um-1\n",
    "    :return: list with lwc, dm, nw, z, and r\n",
    "    \"\"\"\n",
    "    try:\n",
    "        d = np.fromiter(nd.index, dtype=float) / 1e3  # diameter in millimeters\n",
    "        dd = np.fromiter(nd.attrs['dsizes'].values(), dtype=float)  # d_size in um\n",
    "        lwc = (np.pi / 6) * np.sum(nd * d ** 3 * dd)  # g / m3\n",
    "        dm = np.sum(nd * d ** 4 * dd) / np.sum(nd * d ** 3 * dd)  # mm\n",
    "        nw = 1e3 * (4 ** 4 / np.pi) * (lwc / dm ** 4)\n",
    "        z = np.sum(nd * d ** 6 * dd)\n",
    "        r = np.pi * 6e-4 * np.sum(nd * d ** 3 * vel(d) * dd)\n",
    "        # ref = ref_calc(nd=nd, d=d, dd=dd)\n",
    "        # return pd.Series([lwc, dm, nw, z, r])\n",
    "        return [lwc, dm, nw, z, r]\n",
    "    except ZeroDivisionError:\n",
    "        return [np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "\n",
    "\n",
    "def bcksct(ds, instrument, ar=1, j=0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "\n",
    "    :param ds: numpy array of particle diameters. should be in millimeters\n",
    "    :param ar: axis ratio of the particle\n",
    "    :param j: Zenith angle input\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    x_ku = 2 * np.pi * (ds / 2.) / tmatrix_aux.wl_Ku\n",
    "    x_ka = 2 * np.pi * (ds / 2.) / tmatrix_aux.wl_Ka\n",
    "    x_w = 2 * np.pi * (ds / 2.) / tmatrix_aux.wl_W\n",
    "    # Tmatrix calculations\n",
    "    tmat_ku = [radar.radar_xsect(tmatrix.Scatterer(radius=i / 2., wavelength=tmatrix_aux.wl_Ku,\n",
    "                                                   m=refractive.m_w_0C[tmatrix_aux.wl_Ku], axis_ratio=1.0 / ar, thet0=j,\n",
    "                                                   thet=180 - j,\n",
    "                                                   phi0=0., phi=180., radius_type=tmatrix.Scatterer.RADIUS_MAXIMUM)) for\n",
    "               i in ds]\n",
    "    tmat_ka = [radar.radar_xsect(tmatrix.Scatterer(radius=i / 2., wavelength=tmatrix_aux.wl_Ka,\n",
    "                                                   m=refractive.m_w_0C[tmatrix_aux.wl_Ka], axis_ratio=1.0 / ar, thet0=j,\n",
    "                                                   thet=180 - j,\n",
    "                                                   phi0=0., phi=180., radius_type=tmatrix.Scatterer.RADIUS_MAXIMUM)) for\n",
    "               i in ds]\n",
    "    tmat_w = [radar.radar_xsect(tmatrix.Scatterer(radius=i / 2., wavelength=tmatrix_aux.wl_W,\n",
    "                                                  m=refractive.m_w_0C[tmatrix_aux.wl_W], axis_ratio=1.0 / ar, thet0=j,\n",
    "                                                  thet=180 - j,\n",
    "                                                  phi0=0., phi=180., radius_type=tmatrix.Scatterer.RADIUS_MAXIMUM)) for\n",
    "              i in ds]\n",
    "\n",
    "    # Mie calculations\n",
    "    mie_ku = [Mie(x=x_ku[w], m=refractive.m_w_0C[tmatrix_aux.wl_Ku]).qb() * np.pi * (i / 2.) ** 2 for w, i in\n",
    "              enumerate(ds)]\n",
    "    mie_ka = [Mie(x=x_ka[w], m=refractive.m_w_0C[tmatrix_aux.wl_Ka]).qb() * np.pi * (i / 2.) ** 2 for w, i in\n",
    "              enumerate(ds)]\n",
    "    mie_w = [Mie(x=x_w[w], m=refractive.m_w_0C[tmatrix_aux.wl_W]).qb() * np.pi * (i / 2.) ** 2 for w, i in\n",
    "             enumerate(ds)]\n",
    "    df_scatter = pd.DataFrame(\n",
    "        {'T_mat_Ku': tmat_ku, 'T_mat_Ka': tmat_ka, 'T_mat_W': tmat_w, 'Mie_Ku': mie_ku, 'Mie_Ka': mie_ka,\n",
    "         'Mie_W': mie_w}, index=ds)\n",
    "    path_db = f'{path_data}/db'\n",
    "    str_db = f\"sqlite:///{path_db}/backscatter.sqlite\"\n",
    "    df_scatter.to_sql(f'{instrument}', con=str_db, if_exists='replace')\n",
    "    return df_scatter\n",
    "\n",
    "\n",
    "def ref_calc(nd, mie=False):\n",
    "    ds = np.fromiter(nd.attrs['dsizes'].keys(), dtype=float) / 1e3\n",
    "    try:\n",
    "        path_db = f'{path_data}/db'\n",
    "        make_dir(path_db)\n",
    "        str_db = f\"sqlite:///{path_db}/backscatter.sqlite\"\n",
    "        backscatter = pd.read_sql(f\"{nd.attrs['instrument']}\", con=str_db)\n",
    "    except OperationalError:\n",
    "        backscatter = bcksct(ds, nd.attrs['instrument'])\n",
    "    dsizes = np.fromiter(nd.attrs['dsizes'].values(), dtype=float)\n",
    "    ku_wvl = c / 14e9 * 1000\n",
    "    ka_wvl = c / 35e9 * 1000\n",
    "    w_wvl = c / 95e9 * 1000\n",
    "    if mie:\n",
    "        z_ku = (ku_wvl ** 4 / (np.pi ** 5 * 0.93)) * np.sum(backscatter['Mie_Ku'] * nd.values * 1000 * dsizes)\n",
    "        z_ka = (ka_wvl ** 4 / (np.pi ** 5 * 0.93)) * np.sum(backscatter['Mie_Ka'] * nd.values * 1000 * dsizes)\n",
    "        z_w = (w_wvl ** 4 / (np.pi ** 5 * 0.93)) * np.sum(backscatter['Mie_W'] * nd.values * 1000 * dsizes)\n",
    "        return pd.Series({'Ku': 10 * np.log10(z_ku), 'Ka': 10 * np.log10(z_ka), 'W': 10 * np.log10(z_w)},\n",
    "                         name=nd.attrs['instrument'])\n",
    "    else:\n",
    "        z_ku = (ku_wvl ** 4 / (np.pi ** 5 * 0.93)) * backscatter['T_mat_Ku'] * nd.values * 1000 * dsizes\n",
    "        z_ku.index = ds\n",
    "        z_ku.name = 'z_Ku'\n",
    "        # zku_r = np.sum(nd.values * 1000 * (ds ** 6) * dsizes)\n",
    "        z_ka = (ka_wvl ** 4 / (np.pi ** 5 * 0.93)) * backscatter['T_mat_Ka'] * nd.values * 1000 * dsizes\n",
    "        z_ka.index = ds\n",
    "        z_ka.name = 'z_Ka'\n",
    "        z_w = (w_wvl ** 4 / (np.pi ** 5 * 0.93)) * backscatter['T_mat_W'] * nd.values * 1000 * dsizes\n",
    "        z_w.index = ds\n",
    "        z_w.name = 'z_Ka'\n",
    "        instr = ['z_Ku', 'z_Ka', 'z_W']\n",
    "        df_z = pd.concat([z_ku, z_ka, z_w], axis=0, keys=instr, levels=[instr])\n",
    "        return df_z\n",
    "\n",
    "\n",
    "def get_attrs_merged(dt_attrs, _upper, _lower):\n",
    "    d_2ds10 = np.fromiter(dt_attrs['2DS10']['dsizes'].keys(), dtype=float)\n",
    "    d_hvps = np.fromiter(dt_attrs['HVPS']['dsizes'].keys(), dtype=float)\n",
    "    idx_2ds10 = np.abs(d_2ds10 - _upper).argmin() + 1\n",
    "    idx_hvps = np.abs(d_hvps - _upper).argmin()\n",
    "    dt_2ds = dict(itertools.islice(dt_attrs['2DS10']['dsizes'].items(), idx_2ds10))\n",
    "    dt_hvps = dict(itertools.islice(dt_attrs['HVPS']['dsizes'].items(), idx_hvps, len(d_hvps)))\n",
    "    return {**dt_2ds, **dt_hvps}\n",
    "\n",
    "\n",
    "def compute_hr(t, td):\n",
    "    \"\"\"\n",
    "    Computes relative humidity using magnus approximation using\n",
    "    https://earthscience.stackexchange.com/questions/16570/how-to-calculate-relative-humidity-from-temperature-dew-point-and-pressure\n",
    "    :param t: temperature\n",
    "    :param td: dew point temperature\n",
    "    :return: relative humidity\n",
    "    \"\"\"\n",
    "    b = 17.625\n",
    "    _c = 243.04\n",
    "    return 100 * np.exp((_c * b * (td - t) / ((_c + t) * (_c + td))))\n",
    "\n",
    "\n",
    "def get_add_data(aircraft: 'str', indexx) -> pd.DataFrame:\n",
    "    path_db = f'{path_data}/db'\n",
    "    str_db = f\"sqlite:///{path_db}/camp2ex.sqlite\"\n",
    "    if aircraft == 'Lear':\n",
    "        df_add = pd.read_sql_query(\"SELECT time, Temp, Dew, Palt, NevLWC, VaV  FROM Page0_Learjet\", con=str_db)\n",
    "        df_add['time'] = df_add['time'].apply(pd.Timestamp).apply(lambda x: x.tz_localize('UTC'))\n",
    "        df_add['RH'] = df_add[['Temp', 'Dew']].apply(lambda x: compute_hr(t=x['Temp'], td=x['Dew']), axis=1)\n",
    "        df_add['RH'] = df_add['RH'].where(df_add['RH'] <= 100, 100)\n",
    "        df_add.index = df_add['time']\n",
    "        df_add.drop('time', axis=1, inplace=True)\n",
    "        cols = ['temp', 'dew_point', 'altitude', 'lwc', 'vertical_vel', 'RH']\n",
    "        new_cols = {j: cols[i] for i, j in enumerate(list(df_add.columns))}\n",
    "        df_add.rename(columns=new_cols, inplace=True)\n",
    "        df_add = df_add[(df_add.index >= indexx.min().strftime('%Y-%m-%d %X')) &\n",
    "                        (df_add.index <= indexx.max().strftime('%Y-%m-%d %X'))]\n",
    "        return df_add\n",
    "    else:\n",
    "        df_add = pd.read_sql_query(\"SELECT pbm.'time', pbm.' Total_Air_Temp_YANG_MetNav', pbm.' \"\n",
    "                                   \"Dew_Point_YANG_MetNav', pbm.' GPS_Altitude_YANG_MetNav', pbm.' LWC_gm3_LAWSON',  \"\n",
    "                                   \"pbm.' Vertical_Speed_YANG_MetNav', pbm.' Relative_Humidity_YANG_MetNav' FROM \"\n",
    "                                   \"p3b_merge pbm\", con=str_db)\n",
    "        df_add['time'] = df_add['time'].apply(pd.Timestamp).apply(lambda x: x.tz_localize('UTC'))\n",
    "        df_add.index = df_add['time']\n",
    "        df_add.drop('time', axis=1, inplace=True)\n",
    "        cols = ['temp', 'dew_point', 'altitude', 'lwc', 'vertical_vel', 'RH']\n",
    "        new_cols = {j: cols[i] for i, j in enumerate(list(df_add.columns))}\n",
    "        df_add.rename(columns=new_cols, inplace=True)\n",
    "        df_add = df_add[(df_add.index >= indexx.min().strftime('%Y-%m-%d %X')) &\n",
    "                        (df_add.index <= indexx.max().strftime('%Y-%m-%d %X'))]\n",
    "        return df_add\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e563bdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(instrument='Lear', temp=2):\n",
    "    \"\"\"\n",
    "\n",
    "    :param instrument: aircraft\n",
    "    :param temp: temperature for filtering\n",
    "    :return: list of available dataframe in CAMP2ex\n",
    "    \"\"\"\n",
    "    if instrument == 'Lear':\n",
    "        ls_lear = glob.glob(f'{path_data}/pkl/*_Learjet.pkl')\n",
    "        ls_lear = [i for i in ls_lear if not i.split('/')[-1].startswith('Page0')]\n",
    "        ls_temp = glob.glob(f'{path_data}/pkl/Page0*.pkl')[0]\n",
    "        ls_lear.append(ls_temp)\n",
    "        lear_df = [pd.read_pickle(i) for i in ls_lear]\n",
    "        _attrs = [i.attrs for i in lear_df[:-1]]\n",
    "        if temp:\n",
    "            lear_df = [pd.merge(i, lear_df[-1]['Temp'], right_index=True, left_index=True) for i in lear_df[:-1]]\n",
    "            lear_df = [i[i['Temp'] > temp] for i in lear_df]\n",
    "        for i, attrs in enumerate(_attrs):\n",
    "            lear_df[i].attrs = attrs\n",
    "        lear_dd = [dd.from_pandas(i, npartitions=1) for i in lear_df]\n",
    "        del lear_df\n",
    "        return lear_dd\n",
    "    elif instrument == 'P3B':\n",
    "        ls_p3 = glob.glob(f'{path_data}/pkl/*_P3B.pkl')\n",
    "        p3_merged = glob.glob(f'{path_data}/pkl/p3b_merge.pkl')\n",
    "        p3_temp = pd.read_pickle(p3_merged[0])\n",
    "        p3_df = [pd.read_pickle(i) for i in ls_p3]\n",
    "        _attrs = [i.attrs for i in p3_df]\n",
    "        p3_df = [pd.merge(i, p3_temp[' Static_Air_Temp_YANG_MetNav'], left_index=True, right_index=True) for i in p3_df]\n",
    "        temp = 2\n",
    "        for i, df in enumerate(p3_df):\n",
    "            df.attrs = _attrs[i]\n",
    "            df.rename(columns={' Static_Air_Temp_YANG_MetNav': 'Temp'}, inplace=True)\n",
    "            if temp:\n",
    "                df = df[df['Temp'] >= temp]\n",
    "            p3_df[i] = df\n",
    "        p3_dd = [dd.from_pandas(i, npartitions=1) for i in p3_df]\n",
    "        del p3_df\n",
    "        return p3_dd\n",
    "    else:\n",
    "        raise TypeError(f\"{instrument} not available. Use Lear or P3B\")\n",
    "\n",
    "\n",
    "def change_cols(df):\n",
    "    bin_cent = df.attrs['bin_cent']\n",
    "    cols = df.columns\n",
    "    new_cols = {cols[i]: bin_cent[i] for i in range(len(cols))}\n",
    "    df = df.rename(columns=new_cols)\n",
    "    return df\n",
    "\n",
    "\n",
    "@delayed\n",
    "def change_cols(df):\n",
    "    bin_cent = df.attrs['bin_cent']\n",
    "    cols = df.columns\n",
    "    new_cols = {cols[i]: bin_cent[i] for i in range(len(cols))}\n",
    "    df = df.rename(columns=new_cols)\n",
    "    return df\n",
    "\n",
    "\n",
    "def filt_by_instrument(ls_df, hawk=False):\n",
    "    if not hawk:\n",
    "        ls_df = [i for i in ls_df if not i.attrs['instrument'].startswith('Hawk')]\n",
    "        return ls_df\n",
    "    else:\n",
    "        return ls_df\n",
    "\n",
    "\n",
    "def filt_by_cols(ls_df):\n",
    "    # if cols:\n",
    "    cols = [[j for j in i.columns if j.startswith('nsd')] for i in ls_df]\n",
    "    ls_df = [i[cols[j]] for j, i in enumerate(ls_df)]\n",
    "    ls_df = [change_cols(i) for i in ls_df]\n",
    "    return ls_df\n",
    "\n",
    "\n",
    "def get_intervals(ls_df):\n",
    "    cols = [[pd.Interval(j.attrs['sizes'][i], j.attrs['sizes'][i + 1]) for i in\n",
    "             range(len(j.attrs['sizes']) - 1)] for j in ls_df]\n",
    "    cols = [j + [pd.Interval(ls_df[i].attrs['sizes'][-1], list(ls_df[i].attrs['dsizes'].keys())[-1])]\n",
    "            for i, j in enumerate(cols)]\n",
    "    return cols\n",
    "\n",
    "\n",
    "def apply_wgt(df, ovr_upp, ovr_lower):\n",
    "    if (df['2DS10'] != 0) & (df['HVPS'] != 0):\n",
    "        df['2ds10_wgt'] = df['2DS10'] * df['2DS10'].index.values / (ovr_upp - ovr_lower)\n",
    "        df['hvps_wgt'] = df['HVPS'] * (df['HVPS'].index.values - ovr_lower) / (ovr_upp - ovr_lower)\n",
    "        df['nd_res'] = df[['2ds10_wgt', 'hvps_wgt']].dropna(how='all').sum(1)\n",
    "        return df['nd_res']\n",
    "    elif (df['2DS10'] == 0) & (df['HVPS'] != 0):\n",
    "        return df['HVPS']\n",
    "    elif (df['2DS10'] != 0) & (df['HVPS'] == 0):\n",
    "        return df['HVPS']\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def linear_wgt(df1, df2, ovr_upp=1200, ovr_lower=800, method='linear'):\n",
    "    \"\"\"\n",
    "\n",
    "    :param method: method to apply. linear applies Leroy et al. 2014. swal Applies Snesbitt method\n",
    "    :param df1: pandas series with the small diameter sizes (e.g. 2DS10)\n",
    "    :param df2: pandas series with the small diameter sizes (e.g. HVPS)\n",
    "    :param ovr_upp: upper limit for overlapping\n",
    "    :param ovr_lower: lower limit for overlapping\n",
    "    :return: pd series with a composite PSD\n",
    "    \"\"\"\n",
    "    df1.columns = df1.attrs['2DS10']['intervals']\n",
    "    df2.columns = df2.attrs['HVPS']['intervals']\n",
    "    cond1 = (df1.columns.mid >= ovr_lower) & (df1.columns.mid <= ovr_upp)\n",
    "    cond2 = (df2.columns.mid >= ovr_lower) & (df2.columns.mid <= ovr_upp)\n",
    "    _nd_uppr = df1.iloc[:, cond1]\n",
    "    _nd_lower = df2.iloc[:, cond2]\n",
    "    instr = ['2DS10', 'HVPS']\n",
    "    nd_overlap = pd.concat([_nd_uppr.reindex(columns=np.arange(ovr_lower, ovr_upp, 5)),\n",
    "                            _nd_lower.reindex(columns=np.arange(ovr_lower, ovr_upp, 5))], axis=1, keys=instr,\n",
    "                           levels=[instr])\n",
    "    if method == 'linear':\n",
    "        nd_overlap['2ds10_wgt'] = nd_overlap['2DS10'] * (ovr_upp - nd_overlap['2DS10'].columns.values) / \\\n",
    "                                  (ovr_upp - ovr_lower)\n",
    "        nd_overlap['hvps_wgt'] = nd_overlap['HVPS'] * (nd_overlap['HVPS'].index.values - ovr_lower) / \\\n",
    "                                 (ovr_upp - ovr_lower)\n",
    "        nd_overlap['nd_res'] = nd_overlap[['2ds10_wgt', 'hvps_wgt']].dropna(how='all').sum(1)\n",
    "        nd_overlap = nd_overlap.reindex(df1[cond1].index.mid)\n",
    "        nd_overlap.index = df1[cond1].index\n",
    "        res = pd.concat([df1[df1.index.mid <= ovr_lower], nd_overlap['nd_res'], df2[df2.index.mid >= ovr_upp]])\n",
    "        d_d = {i.mid: i.length for i in res.index}\n",
    "        res.index = res.index.mid\n",
    "        res.attrs['dsizes'] = d_d\n",
    "        return res\n",
    "\n",
    "    elif 'snal':\n",
    "        _sdf = nd_overlap.stack()[(((nd_overlap.stack()['2DS10'] == 0) & (nd_overlap.stack()['2DS10'].notnull())) &\n",
    "                                  ((nd_overlap.stack()['HVPS'] == 0) & (nd_overlap.stack()['HVPS'].notnull())))][\n",
    "            '2DS10'].unstack()\n",
    "        _sdd = nd_overlap.stack()[(((nd_overlap.stack()['2DS10'] != 0) & (nd_overlap.stack()['2DS10'].notnull())) &\n",
    "                                  ((nd_overlap.stack()['HVPS'] != 0) & (nd_overlap.stack()['HVPS'].notnull())))]\n",
    "        _sdd['2ds10_wgt'] = _sdd['2DS10'] * (ovr_upp - _sdd.index.get_level_values(1)) / (ovr_upp - ovr_lower)\n",
    "        _sdd['hvps_wgt'] = _sdd['HVPS'] * (_sdd.index.get_level_values(1) - ovr_lower) / (ovr_upp - ovr_lower)\n",
    "        _sdd['nd_res'] = _sdd[['2ds10_wgt', 'hvps_wgt']].sum(1)\n",
    "        _sdd = _sdd['nd_res'].unstack()\n",
    "        _sdc = nd_overlap.stack()[(((nd_overlap.stack()['2DS10'] == 0) | (nd_overlap.stack()['2DS10'].isnull())) &\n",
    "                                  (nd_overlap.stack()[\"HVPS\"] != 0))]['HVPS'].unstack()\n",
    "        _sds = nd_overlap.stack()[(((nd_overlap.stack()['HVPS'] == 0) | (nd_overlap.stack()['HVPS'].isnull())) &\n",
    "                                  (nd_overlap.stack()[\"2DS10\"] != 0))]['2DS10'].unstack()\n",
    "        res = pd.concat([_sdd, _sdc, _sds, _sdf], axis=1).sort_index().dropna(how='all',\n",
    "                                                                              axis='columns').groupby(level=0,\n",
    "                                                                                                      axis=1).sum()\n",
    "        res = res[df1.iloc[:, cond1].columns.mid]\n",
    "        res.columns = df1.iloc[:, cond1].columns\n",
    "        res = pd.concat([df1.iloc[:, df1.columns.mid <= ovr_lower], res, df2.iloc[:, df2.columns.mid >= ovr_upp]],\n",
    "                        axis=1)\n",
    "        d_d = {i.mid: i.length for i in res.columns}\n",
    "        res.columns = res.columns.mid\n",
    "        res.attrs['dsizes'] = d_d\n",
    "        res.attrs['instrument'] = 'Composite_PSD'\n",
    "        return res\n",
    "\n",
    "\n",
    "def vel(d):\n",
    "    return -0.1021 + 4.932 * d - 0.955 * d ** 2 + 0.07934 * d ** 3 - 0.0023626 * d ** 4\n",
    "\n",
    "\n",
    "def pds_parameters(nd):\n",
    "    \"\"\"\n",
    "    Compute the psd parameters\n",
    "    :param nd: partice size distribution in # L-1 um-1\n",
    "    :return: list with lwc, dm, nw, z, and r\n",
    "    \"\"\"\n",
    "    d = np.fromiter(nd.columns, dtype=float) / 1e3  # diameter in millimeters\n",
    "    d_d = np.fromiter(nd.attrs['dsizes'].values(), dtype=float) / 1e3  # d_size in um\n",
    "    lwc = nd.mul(1e6).mul(d ** 3).mul(d_d) * (np.pi / (6 * 1000))  # g / m3\n",
    "    dm = nd.mul(d ** 4).mul(d_d).sum(1) / nd.mul(d ** 3).mul(d_d).sum(1)  # mm\n",
    "    nw = 1e3 * (4 ** 4 / np.pi) * (lwc.sum(1) / dm ** 4)\n",
    "    z = nd.mul(d ** 6).mul(d_d)\n",
    "    _ = ['lwc', 'dm', 'nw', 'z']\n",
    "    return pd.concat([lwc, dm, nw, z], axis=1, keys=_, levels=[_])\n",
    "\n",
    "\n",
    "def bcksct(ds, instrument, _lower, _upper, ar=1, j=0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "\n",
    "    :param _upper: upper diameter of the pds\n",
    "    :param _lower: upper diameter of the pds\n",
    "    :param instrument:\n",
    "    :param ds: numpy array of particle diameters. should be in millimeters\n",
    "    :param ar: axis ratio of the particle\n",
    "    :param j: Zenith angle input\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    x_ku = 2 * np.pi * (ds / 2.) / tmatrix_aux.wl_Ku\n",
    "    x_ka = 2 * np.pi * (ds / 2.) / tmatrix_aux.wl_Ka\n",
    "    x_w = 2 * np.pi * (ds / 2.) / tmatrix_aux.wl_W\n",
    "    # Tmatrix calculations\n",
    "    tmat_ku = [radar.radar_xsect(tmatrix.Scatterer(radius=i / 2., wavelength=tmatrix_aux.wl_Ku,\n",
    "                                                   m=refractive.m_w_0C[tmatrix_aux.wl_Ku], axis_ratio=1.0 / ar, thet0=j,\n",
    "                                                   thet=180 - j,\n",
    "                                                   phi0=0., phi=180., radius_type=tmatrix.Scatterer.RADIUS_MAXIMUM)) for\n",
    "               i in ds]\n",
    "    tmat_ka = [radar.radar_xsect(tmatrix.Scatterer(radius=i / 2., wavelength=tmatrix_aux.wl_Ka,\n",
    "                                                   m=refractive.m_w_0C[tmatrix_aux.wl_Ka], axis_ratio=1.0 / ar, thet0=j,\n",
    "                                                   thet=180 - j,\n",
    "                                                   phi0=0., phi=180., radius_type=tmatrix.Scatterer.RADIUS_MAXIMUM)) for\n",
    "               i in ds]\n",
    "    tmat_w = [radar.radar_xsect(tmatrix.Scatterer(radius=i / 2., wavelength=tmatrix_aux.wl_W,\n",
    "                                                  m=refractive.m_w_0C[tmatrix_aux.wl_W], axis_ratio=1.0 / ar, thet0=j,\n",
    "                                                  thet=180 - j,\n",
    "                                                  phi0=0., phi=180., radius_type=tmatrix.Scatterer.RADIUS_MAXIMUM)) for\n",
    "              i in ds]\n",
    "\n",
    "    # Mie calculations\n",
    "    mie_ku = [Mie(x=x_ku[w], m=refractive.m_w_0C[tmatrix_aux.wl_Ku]).qb() * np.pi * (i / 2.) ** 2 for w, i in\n",
    "              enumerate(ds)]\n",
    "    mie_ka = [Mie(x=x_ka[w], m=refractive.m_w_0C[tmatrix_aux.wl_Ka]).qb() * np.pi * (i / 2.) ** 2 for w, i in\n",
    "              enumerate(ds)]\n",
    "    mie_w = [Mie(x=x_w[w], m=refractive.m_w_0C[tmatrix_aux.wl_W]).qb() * np.pi * (i / 2.) ** 2 for w, i in\n",
    "             enumerate(ds)]\n",
    "    df_scatter = pd.DataFrame(\n",
    "        {'T_mat_Ku': tmat_ku, 'T_mat_Ka': tmat_ka, 'T_mat_W': tmat_w, 'Mie_Ku': mie_ku, 'Mie_Ka': mie_ka,\n",
    "         'Mie_W': mie_w}, index=ds)\n",
    "    path_db = f'{path_data}/db'\n",
    "    make_dir(path_db)\n",
    "    str_db = f\"sqlite:///{path_db}/backscatter_{_lower}_{_upper}.sqlite\"\n",
    "    df_scatter.to_sql(f'{instrument}', con=str_db, if_exists='replace')\n",
    "    return df_scatter\n",
    "\n",
    "\n",
    "def ref_calc(nd, _lower, _upper, mie=False):\n",
    "    ds = np.fromiter(nd.attrs['dsizes'].keys(), dtype=float) / 1e3\n",
    "    try:\n",
    "        path_db = f'{path_data}/db'\n",
    "        str_db = f\"sqlite:///{path_db}/backscatter_{_lower}_{_upper}.sqlite\"\n",
    "        backscatter = pd.read_sql(f\"{nd.attrs['instrument']}\", con=str_db)\n",
    "    except OperationalError:\n",
    "        backscatter = bcksct(ds, nd.attrs['instrument'], _lower=_lower, _upper=_upper)\n",
    "    dsizes = np.fromiter(nd.attrs['dsizes'].values(), dtype=float) / 1e3\n",
    "    ku_wvl = c / 14e9 * 1000\n",
    "    ka_wvl = c / 35e9 * 1000\n",
    "    w_wvl = c / 95e9 * 1000\n",
    "    wvl = ['z_Ku', 'z_Ka', 'z_W']\n",
    "    if mie:\n",
    "        z_ku = (ku_wvl ** 4 / (np.pi ** 5 * 0.93)) * nd.mul(1e6).mul(backscatter['Mie_Ku'].values,\n",
    "                                                                     axis='columns').mul(dsizes)\n",
    "        z_ka = (ka_wvl ** 4 / (np.pi ** 5 * 0.93)) * nd.mul(1e6).mul(backscatter['Mie_Ka'].values,\n",
    "                                                                     axis='columns').mul(dsizes)\n",
    "        z_w = (w_wvl ** 4 / (np.pi ** 5 * 0.93)) * nd.mul(1e6).mul(backscatter['Mie_W'].values,\n",
    "                                                                   axis='columns').mul(dsizes)\n",
    "        df_z = pd.concat([z_ku, z_ka, z_w], axis=1, keys=wvl, levels=[wvl])\n",
    "        return df_z\n",
    "    else:\n",
    "        z_ku = (ku_wvl ** 4 / (np.pi ** 5 * 0.93)) * nd.mul(1e6).mul(backscatter['T_mat_Ku'].values,\n",
    "                                                                     axis='columns').mul(dsizes)\n",
    "        z_ka = (ka_wvl ** 4 / (np.pi ** 5 * 0.93)) * nd.mul(1e6).mul(backscatter['T_mat_Ka'].values,\n",
    "                                                                     axis='columns').mul(dsizes)\n",
    "        z_w = (w_wvl ** 4 / (np.pi ** 5 * 0.93)) * nd.mul(1e6).mul(backscatter['T_mat_W'].values,\n",
    "                                                                   axis='columns').mul(dsizes)\n",
    "        df_z = pd.concat([z_ku, z_ka, z_w], axis=1, keys=wvl, levels=[wvl])\n",
    "        return df_z\n",
    "\n",
    "\n",
    "def compute_hr(t, td):\n",
    "    \"\"\"\n",
    "    Computes relative humidity using magnus approximation using\n",
    "    https://earthscience.stackexchange.com/questions/16570/how-to-calculate-relative-humidity-from-temperature-dew-point-and-pressure\n",
    "    :param t: temperature\n",
    "    :param td: dew point temperature\n",
    "    :return: relative humidity\n",
    "    \"\"\"\n",
    "    b = 17.625\n",
    "    _c = 243.04\n",
    "    return 100 * np.exp((_c * b * (td - t) / ((_c + t) * (_c + td))))\n",
    "\n",
    "\n",
    "def get_add_data(aircraft: 'str', indexx) -> pd.DataFrame:\n",
    "    path_par = f'{path_data}/parquet'\n",
    "    if aircraft == 'Lear':\n",
    "        str_db = f'{path_par}/Page0_Learjet.parquet'\n",
    "        df_add = pd.read_parquet(str_db, columns=['Temp', 'Dew', 'Palt', 'NevLWC', 'VaV'])\n",
    "        df_add['RH'] = compute_hr(t=df_add['Temp'], td=df_add['Dew'])\n",
    "        df_add['RH'] = df_add['RH'].where(df_add['RH'] <= 100, 100)\n",
    "        cols = ['temp', 'dew_point', 'altitude', 'lwc', 'vertical_vel', 'RH']\n",
    "        new_cols = {j: cols[i] for i, j in enumerate(list(df_add.columns))}\n",
    "        df_add.rename(columns=new_cols, inplace=True)\n",
    "        df_add = df_add[(df_add.index >= indexx.min().strftime('%Y-%m-%d %X')) &\n",
    "                        (df_add.index <= indexx.max().strftime('%Y-%m-%d %X'))]\n",
    "        return df_add\n",
    "    else:\n",
    "        str_db = f'{path_par}/p3b_merge.parquet'\n",
    "        df_add = pd.read_parquet(str_db, columns=[' Total_Air_Temp_YANG_MetNav', ' Dew_Point_YANG_MetNav',\n",
    "                                                  ' GPS_Altitude_YANG_MetNav', ' LWC_gm3_LAWSON',\n",
    "                                                  ' Vertical_Speed_YANG_MetNav', ' Relative_Humidity_YANG_MetNav'])\n",
    "        df_add['time'] = df_add['time'].apply(pd.Timestamp).apply(lambda x: x.tz_localize('UTC'))\n",
    "        cols = ['temp', 'dew_point', 'altitude', 'lwc', 'vertical_vel', 'RH']\n",
    "        new_cols = {j: cols[i] for i, j in enumerate(list(df_add.columns))}\n",
    "        df_add.rename(columns=new_cols, inplace=True)\n",
    "        return df_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "629aeae2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039e3f9df0d1401e9eb5c2ad75cb8acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>SLURMCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n    â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster = SLURMCluster(queue=\"seseml\",\n",
    "                       memory='200GB',\n",
    "                       cores=40,\n",
    "                       processes=1,\n",
    "                       walltime='24:00:00',\n",
    "                       scheduler_options={'host': '172.22.179.3:7223', 'dashboard_address': ':7999'})\n",
    "\n",
    "cluster.scale(jobs=4)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "970ddf80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://172.22.179.3:7223</li>\n",
       "  <li><b>Dashboard: </b><a href='/proxy/7999/status' target='_blank'>/proxy/7999/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://172.22.179.3:7223' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "884e0767",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_112602/710830378.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0m_upper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m800\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m_lower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mls_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maircraft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mls_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilt_by_instrument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mls_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mls_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilt_by_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mls_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_112602/2634063704.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(instrument, temp)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mls_lear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{path_data}/pkl/*_Learjet.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mls_lear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mls_lear\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Page0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mls_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{path_data}/pkl/Page0*.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mls_lear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mls_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mlear_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mls_lear\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "aircraft = 'Lear'\n",
    "_upper = 800\n",
    "_lower = 400\n",
    "ls_df = get_data(aircraft, temp=2)\n",
    "ls_df = filt_by_instrument(ls_df)\n",
    "ls_df = filt_by_cols(ls_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4516a43e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26110/3228478461.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mls_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdt_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minstr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mls_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdf_concat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt_attrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/camp2ex_proj/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/camp2ex_proj/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    358\u001b[0m     )\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/camp2ex_proj/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0mcons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"concat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_result_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/camp2ex_proj/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__finalize__\u001b[0;34m(self, other, method, **kwargs)\u001b[0m\n\u001b[1;32m   5547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"concat\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5548\u001b[0m             \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5549\u001b[0;31m             \u001b[0mcheck_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobjs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck_attrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5551\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/camp2ex_proj/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   5547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"concat\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5548\u001b[0m             \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5549\u001b[0;31m             \u001b[0mcheck_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobjs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck_attrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5551\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "ls_df = [i.compute() for i in ls_df]\n",
    "_dp = [i.duplicated().any() for i in ls_df]\n",
    "instr = [i.attrs['instrument'] for i in ls_df]\n",
    "attrs = [i.attrs for i in ls_df]\n",
    "dt_attrs = {instr[i]: j for i, j in enumerate(attrs)}\n",
    "df_concat = pd.concat(compute(*ls_df), axis=1, keys=instr, levels=[instr])\n",
    "df_concat.attrs = dt_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ad0c0b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.2'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7e224431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60722, 61)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_df[3].compute().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "85a5969f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26110/2585480628.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mls_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# df_concat.attrs = dt_attrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/camp2ex_proj/lib/python3.9/site-packages/dask/dataframe/multi.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(dfs, axis, join, interleave_partitions, ignore_unknown_divisions, ignore_order, **kwargs)\u001b[0m\n\u001b[1;32m   1208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mknown_divisions\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1210\u001b[0;31m             return concat_indexed_dataframes(\n\u001b[0m\u001b[1;32m   1211\u001b[0m                 \u001b[0mdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda3/envs/camp2ex_proj/lib/python3.9/site-packages/dask/dataframe/multi.py\u001b[0m in \u001b[0;36mconcat_indexed_dataframes\u001b[0;34m(dfs, axis, join, ignore_order, **kwargs)\u001b[0m\n\u001b[1;32m    982\u001b[0m     \u001b[0mwarn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"ignore_order\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mignore_order\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m     meta = methods.concat(\n\u001b[0m\u001b[1;32m    985\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_meta\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/camp2ex_proj/lib/python3.9/site-packages/dask/dataframe/dispatch.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(dfs, axis, join, uniform, filter_warning, ignore_index, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         return func(\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mdfs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/camp2ex_proj/lib/python3.9/site-packages/dask/dataframe/backends.py\u001b[0m in \u001b[0;36mconcat_pandas\u001b[0;34m(dfs, axis, join, uniform, filter_warning, ignore_index, **kwargs)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;31m# Support concatenating indices along axis 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/camp2ex_proj/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/camp2ex_proj/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    358\u001b[0m     )\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/camp2ex_proj/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0mcons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"concat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_result_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/camp2ex_proj/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__finalize__\u001b[0;34m(self, other, method, **kwargs)\u001b[0m\n\u001b[1;32m   5547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"concat\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5548\u001b[0m             \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5549\u001b[0;31m             \u001b[0mcheck_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobjs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck_attrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5551\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/camp2ex_proj/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   5547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"concat\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5548\u001b[0m             \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5549\u001b[0;31m             \u001b[0mcheck_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobjs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck_attrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5551\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "df_concat = dd.concat(ls_df, axis=1, keys=instr, levels=[instr])\n",
    "# df_concat.attrs = dt_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f41d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if aircraft == 'Lear':\n",
    "    rdm_idx = pd.date_range(start='2019-09-07 2:31:45', periods=150, tz='UTC', freq='S')  # for Lear\n",
    "else:\n",
    "    rdm_idx = pd.date_range(start='2019-09-06 23:58:30', periods=150, tz='UTC', freq='S')  # for P3B\n",
    "#     rdm_idx = pd.date_range(start='2019-09-07 00:00:00', periods=150, tz='UTC', freq='S')  # for P3B\n",
    "\n",
    "\n",
    "# rdm_idx = df_concat.index\n",
    "indexx = rdm_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cc1466",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ls = []\n",
    "ls_z = []\n",
    "params = pd.DataFrame(index=indexx, columns=['lwc', 'dm', 'nw', 'z', 'r'])\n",
    "for i in indexx:\n",
    "    df = df_concat.loc[i]\n",
    "    res1 = df.unstack().T\n",
    "    if res1['2DS10'].dropna(how='any').empty:\n",
    "        df1 = pd.Series(index=df_concat.attrs['2DS10']['bin_cent'], dtype='float64', name='2DS10')\n",
    "    elif len(res1['2DS10'].dropna(how='any')) < len(df_concat.attrs['2DS10']['bin_cent']):\n",
    "        df1 = pd.Series(index=df_concat.attrs['2DS10']['bin_cent'], dtype='float64', name='2DS10')\n",
    "    else:\n",
    "        df1 = res1['2DS10'].dropna(how='any')\n",
    "\n",
    "    if res1['HVPS'].dropna(how='any').empty:\n",
    "        df2 = pd.Series(index=df_concat.attrs['HVPS']['bin_cent'], dtype='float64',  name='HVPS')\n",
    "    elif len(res1['HVPS'].dropna(how='any')) < len(df_concat.attrs['HVPS']['bin_cent']):\n",
    "        df2 = pd.Series(index=df_concat.attrs['HVPS']['bin_cent'], dtype='float64', name='HVPS')\n",
    "    else:\n",
    "        df2 = res1['HVPS'].dropna(how='any')\n",
    "    df1.attrs = df_concat.attrs\n",
    "    df2.attrs = df_concat.attrs\n",
    "    a = linear_wgt(df1=df1, df2=df2, ovr_upp=_upper, ovr_lower=_lower, method='snal')\n",
    "    a.attrs['dsizes'] = attrs_merged\n",
    "    a.attrs['instrument'] = 'Composite_PSD'\n",
    "    params.loc[i] = pds_parameters(a)\n",
    "    ls_z.append(ref_calc(a))\n",
    "    ls.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7622da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reflectivity = pd.concat(ls_z, axis=1).T.set_index(indexx)\n",
    "df_merged = pd.concat(ls, axis=1).T.set_index(indexx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dceefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day = df_merged.groupby(df_merged.index.floor('d'))\n",
    "keys = list(df_day.groups.keys())\n",
    "del df_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4d6955",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key in keys:\n",
    "    airc = ls_df[0].attrs['aircraft']\n",
    "    df = df_merged.groupby(df_merged.index.floor('d')).get_group(key)\n",
    "#     df = df[(df.index > index.min()) & (df.index > index.max()) ]\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    cbar = ax.pcolormesh(df.index, df.columns * 1e-3, np.log10(df.T * 1e6), vmin=0, vmax=10, cmap=my_cmap)\n",
    "    ax.hlines(_upper * 1e-3, df_merged.index.min(), df_merged.index.max(), linewidth=1, color='k', \n",
    "              linestyles='--')\n",
    "    ax.hlines(_lower * 1e-3, df_merged.index.min(), df_merged.index.max(), linewidth=1, color='k', \n",
    "              linestyles='--')\n",
    "    ax.hlines(df_concat['HVPS'].columns.min() * 1e-3, df_merged.index.min(), \n",
    "              df_merged.index.max(), linewidth=1, color='b', linestyles='--')\n",
    "\n",
    "    plt.colorbar(cbar, pad=0.01, aspect=20)  # .set_ticks(np.arange(0,,1))\n",
    "    ax.set_ylabel(r'$Diameter \\  (mm)$', fontsize='x-large')\n",
    "    ax.set_xlabel('$Time \\  (UTC)$', fontsize='x-large')\n",
    "    plt.title('$N(D), \\log_{10} (\\# \\ m^{-3} mm^{-1}) $', position=(0.8, 0.1), fontsize='x-large')\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    ax.set_yscale('log')\n",
    "    title = f\"{key: %Y-%m-%d} UTC - {aircraft}\"\n",
    "    fig.suptitle(title, fontsize=14, fontweight='bold', y=0.99)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7a166254",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs_merged = get_attrs_merged(df_concat.attrs, _upper, _lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6055b212",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keys:\n",
    "    airc = ls_df[0].attrs['aircraft']\n",
    "    df = df_merged.groupby(df_merged.index.floor('d')).get_group(key)\n",
    "    df_z = df_concat.groupby(df_concat.index.floor('d')).get_group(key)\n",
    "    # df_z = df_z.loc[(df_z.index > '2019-09-07 02:33:00') & (df_z.index < '2019-09-07 02:33:55')]\n",
    "    df_z = df_z.loc[(df_z.index > indexx.min()) & (df_z.index < indexx.max())]\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 10))\n",
    "    cbar = ax3.pcolormesh(df.index, df.columns * 1e-3, np.log10(df.T * 1e6), vmin=0, vmax=10, cmap=my_cmap)\n",
    "    cbar2 = ax1.pcolormesh(df_z['2DS10'].index, df_z['2DS10'].columns * 1e-3, np.log10(df_z['2DS10'].T * 1e6), vmin=0,\n",
    "                           vmax=10, cmap=my_cmap)\n",
    "    cbar3 = ax2.pcolormesh(df_z['HVPS'].index, df_z['HVPS'].columns * 1e-3, np.log10(df_z['HVPS'].T * 1e6), vmin=0,\n",
    "                           vmax=10, cmap=my_cmap)    \n",
    "    plt.colorbar(cbar, ax=ax1, pad=0.01, aspect=20, label='$N(D), \\log_{10} (\\# \\ m^{-3} mm^{-1}) $')  # .set_ticks(np.arange(0,,1))\n",
    "    plt.colorbar(cbar2, ax=ax2, pad=0.01, aspect=20, label='$N(D), \\log_{10} (\\# \\ m^{-3} mm^{-1}) $')  # .set_ticks(np.arange(0,,1))\n",
    "    plt.colorbar(cbar3, ax=ax3, pad=0.01, aspect=20,label='$N(D), \\log_{10} (\\# \\ m^{-3} mm^{-1}) $')  # .set_ticks(np.arange(0,,1))\n",
    "#     ax1.hlines(_upper * 1e-3, df_merged.index.min(), df_merged.index.max(), linewidth=1, color='k', \n",
    "#               linestyles='--')\n",
    "#     ax1.hlines(_lower * 1e-3, df_merged.index.min(), df_merged.index.max(), linewidth=1, color='k', \n",
    "#               linestyles='--')\n",
    "#     ax1.hlines(df_concat['HVPS'].columns.min() * 1e-3, df_merged.index.min(), \n",
    "#               df_merged.index.max(), linewidth=1, color='b', linestyles='--')\n",
    "    \n",
    "#     ax2.hlines(_upper * 1e-3, df_merged.index.min(), df_merged.index.max(), linewidth=1, color='k', \n",
    "#               linestyles='--')\n",
    "#     ax2.hlines(_lower * 1e-3, df_merged.index.min(), df_merged.index.max(), linewidth=1, color='k', \n",
    "# #               linestyles='--')\n",
    "#     ax2.hlines(df_concat['HVPS'].columns.min() * 1e-3, df_merged.index.min(), \n",
    "#               df_merged.index.max(), linewidth=1, color='b', linestyles='--')\n",
    "    ax3.hlines(_upper * 1e-3, df_merged.index.min(), df_merged.index.max(), linewidth=1, color='k', \n",
    "              linestyles='--')\n",
    "    ax3.hlines(_lower * 1e-3, df_merged.index.min(), df_merged.index.max(), linewidth=1, color='k', \n",
    "              linestyles='--')\n",
    "    ax3.hlines(df_concat['HVPS'].columns.min() * 1e-3, df_merged.index.min(), \n",
    "              df_merged.index.max(), linewidth=1, color='b', linestyles='--')\n",
    "#     ax1.ylabel(r'$Diameter \\  (mm)$', fontsize='x-large')\n",
    "    fig.supylabel(r'$Diameter \\  (mm)$', fontsize='x-large')\n",
    "    ax3.set_xlabel('$Time \\  (UTC)$', fontsize='x-large')\n",
    "    ax1.set_title('$2DS$')\n",
    "#     ax1.set_title('$N(D), \\log_{10} (\\# \\ m^{-3} mm^{-1}) $', position=(0.8, 0.1), fontsize='x-large')\n",
    "    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    ax1.set_yscale('log')\n",
    "    ax2.set_yscale('log')\n",
    "    ax3.set_yscale('log')\n",
    "    ax2.set_title('HVPS')\n",
    "    ax3.set_title('Combined PSD')\n",
    "    ax1.set_xlim(df_merged.index.min(), df_merged.index.max())\n",
    "    ax2.set_xlim(df_merged.index.min(), df_merged.index.max())\n",
    "    ax3.set_xlim(df_merged.index.min(), df_merged.index.max())\n",
    "    ax1.set_ylim(0.01, 40)\n",
    "    ax2.set_ylim(0.01, 40)\n",
    "    ax3.set_ylim(0.01, 40)\n",
    "\n",
    "    title = f\"{key: %Y-%m-%d} UTC - {aircraft}\"\n",
    "    fig.suptitle(title, fontsize=14, fontweight='bold', y=0.99)\n",
    "    plt.tight_layout()\n",
    "    # path_save = f'{path_data}/results/bimodality/flight/{aircraft}'\n",
    "    # make_dir(path_save)\n",
    "    # fig.savefig(f\"{path_save}/{aircraft}_{key:%Y%m%d}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af2bd1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in df_merged.index[50:60]:\n",
    "    fig, (ax, ax1) = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n",
    "    y= df_merged.loc[i].replace(0, np.nan) * 1e6\n",
    "    ax1.step(x=df_merged.loc[i].index.values * 1e-3, y=y, where='post', c='k', lw=2, label= 'Combined PSD')\n",
    "    \n",
    "    ax.step(x=df_concat['2DS10'].loc[i].index.values * 1e-3, \n",
    "            y=df_concat['2DS10'].loc[i].replace(0, np.nan) * 1e6, where='post', label='2DS', c='k')\n",
    "    ax.step(x=df_concat['HVPS'].loc[i].index.values * 1e-3, \n",
    "            y=df_concat['HVPS'].loc[i].replace(0, np.nan) * 1e6, where='post', label='HVPS', c='b')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('Particle size (mm)')\n",
    "    ax.set_ylabel('Concentration (# m-3 mm-1)')\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.set_xscale('log')\n",
    "    ax.legend()\n",
    "    ax1.legend()\n",
    "\n",
    "    ax1.set_xlabel('Particle size (mm)')\n",
    "    title = f\"{i: %Y-%m-%d %X} UTC - {aircraft}\"\n",
    "    fig.suptitle(title, fontsize=14, fontweight='bold', y=0.99)\n",
    "#     ax1.set_ylabel('Concentration (# m-3 m-1)')\n",
    "    ax1.grid(which='both')\n",
    "    ax.grid(which='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9f7fc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key in keys:\n",
    "    airc = ls_df[0].attrs['aircraft']\n",
    "    df = df_merged.groupby(df_merged.index.floor('d')).get_group(key)\n",
    "    df_z = df_reflectivity.groupby(df_merged.index.floor('d')).get_group(key)\n",
    "    df = df[df > 0]\n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(12, 10))\n",
    "    cbar = ax1.pcolormesh(df.index, df.columns * 1e-3, np.log10(df.T * 1e6), vmin=0, vmax=10, cmap=my_cmap)\n",
    "    cbar2 = ax2.pcolormesh(df_z['z_Ku'].index, df_z['z_Ku'].columns, 10 * np.log10(df_z['z_Ku'].T), vmin=-10,\n",
    "                           vmax=50, cmap='jet')\n",
    "    cbar3 = ax3.pcolormesh(df_z['z_Ka'].index, df_z['z_Ka'].columns, 10 * np.log10(df_z['z_Ka'].T), vmin=-10,\n",
    "                           vmax=50, cmap='jet')\n",
    "    cbar4 = ax4.pcolormesh(df_z['z_W'].index, df_z['z_W'].columns, 10 * np.log10(df_z['z_W'].T), vmin=-10,\n",
    "                           vmax=50, cmap='jet')\n",
    "\n",
    "    plt.colorbar(cbar, ax=ax1, pad=0.01, aspect=20)  # .set_ticks(np.arange(0,,1))\n",
    "    plt.colorbar(cbar2, ax=ax2, pad=0.01, aspect=20)  # .set_ticks(np.arange(0,,1))\n",
    "    plt.colorbar(cbar3, ax=ax3, pad=0.01, aspect=20)  # .set_ticks(np.arange(0,,1))\n",
    "    plt.colorbar(cbar4, ax=ax4, pad=0.01, aspect=20)  # .set_ticks(np.arange(0,,1))\n",
    "    ax1.set_ylabel(r'$Diameter \\  (mm)$', fontsize='x-large')\n",
    "    ax1.set_xlabel('$Time \\  (UTC)$', fontsize='x-large')\n",
    "    ax1.set_title('$N(D), \\log_{10} (\\# \\ m^{-3} mm^{-1}) $', position=(0.8, 0.1), fontsize='x-large')\n",
    "    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    ax1.set_yscale('log')\n",
    "    ax2.set_yscale('log')\n",
    "    ax3.set_yscale('log')\n",
    "    ax4.set_yscale('log')\n",
    "    ax2.set_title('Ku-band radar reflectivity')\n",
    "    ax3.set_title('Ka-band radar reflectivity')\n",
    "    ax4.set_title('W-band radar reflectivity')\n",
    "    title = f\"{key: %Y-%m-%d} UTC - {aircraft}\"\n",
    "    fig.suptitle(title, fontsize=14, fontweight='bold', y=0.99)\n",
    "    plt.tight_layout()\n",
    "    # path_save = f'{path_data}/results/bimodality/flight/{aircraft}'\n",
    "    # make_dir(path_save)\n",
    "    # fig.savefig(f\"{path_save}/{aircraft}_{key:%Y%m%d}.jpg\")\n",
    "    plt.show()\n",
    "    print(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296c40f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_merg = xr.Dataset(\n",
    "    data_vars=dict(\n",
    "        merge_psd=([\"time\",\"diameter\"],df_merged.to_numpy()),\n",
    "        refl_ku=([\"time\",\"diameter\"],df_reflectivity['z_Ku'].to_numpy()),\n",
    "        refl_ka=([\"time\",\"diameter\"],df_reflectivity['z_Ka'].to_numpy()),\n",
    "        refl_w=([\"time\",\"diameter\"],df_reflectivity['z_W'].to_numpy()),\n",
    "        lwc = ([\"time\"], params['lwc'].to_numpy()),\n",
    "        nw = ([\"time\"], params['nw'].to_numpy()),\n",
    "        dm = ([\"time\"], params['dm'].to_numpy()),\n",
    "        z = ([\"time\"], params['z'].to_numpy()),\n",
    "        r = ([\"time\"], params['r'].to_numpy())),\n",
    "\n",
    "    coords=dict(\n",
    "        time=([\"time\"],np.array([i.to_datetime64() for i in df_merged.index])),\n",
    "        diameter=([\"diameter\"],df_merged.columns)),\n",
    "    attrs=dict(description=\"combined psd\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe19502",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_merg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace11851",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4.5))\n",
    "cbar = ax.pcolormesh(xr_merg.time.values, xr_merg.diameter.values * 1e-3, \n",
    "                     np.log10(xr_merg.merge_psd.T.values * 1e6), vmin=0, vmax=10, cmap=my_cmap)\n",
    "plt.colorbar(cbar, pad=0.01, aspect=20)  # .set_ticks(np.arange(0,,1))\n",
    "ax.set_ylabel(r'$Diameter \\  (mm)$', fontsize='x-large')\n",
    "ax.set_xlabel('$Time \\  (UTC)$', fontsize='x-large')\n",
    "plt.title('$N(D), \\log_{10} (\\# \\ m^{-3} mm^{-1}) $', position=(0.8, 0.1), fontsize='x-large')\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "ax.set_yscale('log')\n",
    "title = f\"{key: %Y-%m-%d} UTC - {aircraft}\"\n",
    "fig.suptitle(title, fontsize=14, fontweight='bold', y=0.99)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74bff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4.5))\n",
    "cbar = ax.pcolormesh(xr_merg.time.values, xr_merg.diameter.values * 1e-3, \n",
    "                     10 * np.log10(xr_merg.refl_ku.T.values), vmin=-10, vmax=50, cmap='jet')\n",
    "plt.colorbar(cbar, pad=0.01, aspect=20)  # .set_ticks(np.arange(0,,1))\n",
    "ax.set_ylabel(r'$Diameter \\  (mm)$', fontsize='x-large')\n",
    "ax.set_xlabel('$Time \\  (UTC)$', fontsize='x-large')\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "ax.set_yscale('log')\n",
    "title = f\"{key: %Y-%m-%d} UTC - {aircraft}\"\n",
    "fig.suptitle(title, fontsize=14, fontweight='bold', y=0.99)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f107dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4.5))\n",
    "cbar = ax.pcolormesh(xr_merg.time.values, xr_merg.diameter.values * 1e-3, \n",
    "                     10 * np.log10(xr_merg.refl_ka.T.values), vmin=-10, vmax=50, cmap='jet')\n",
    "plt.colorbar(cbar, pad=0.01, aspect=20)  # .set_ticks(np.arange(0,,1))\n",
    "ax.set_ylabel(r'$Diameter \\  (mm)$', fontsize='x-large')\n",
    "ax.set_xlabel('$Time \\  (UTC)$', fontsize='x-large')\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "ax.set_yscale('log')\n",
    "title = f\"{key: %Y-%m-%d} UTC - {aircraft}\"\n",
    "fig.suptitle(title, fontsize=14, fontweight='bold', y=0.99)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7667eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4.5))\n",
    "cbar = ax.pcolormesh(xr_merg.time.values, xr_merg.diameter.values * 1e-3, \n",
    "                     10 * np.log10(xr_merg.refl_w.T.values), vmin=-10, vmax=50, cmap='jet')\n",
    "plt.colorbar(cbar, pad=0.01, aspect=20)  # .set_ticks(np.arange(0,,1))\n",
    "ax.set_ylabel(r'$Diameter \\  (mm)$', fontsize='x-large')\n",
    "ax.set_xlabel('$Time \\  (UTC)$', fontsize='x-large')\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "ax.set_yscale('log')\n",
    "title = f\"{key: %Y-%m-%d} UTC - {aircraft}\"\n",
    "fig.suptitle(title, fontsize=14, fontweight='bold', y=0.99)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba0fa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_sel =  xr_merg.sel(time=slice('2019-09-07 2:31:45', '2019-09-07 2:34:00'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d3dc0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4.5))\n",
    "cbar = ax.pcolormesh(xr_sel.time.values, xr_sel.diameter.values * 1e-3, \n",
    "                     np.log10(xr_sel.merge_psd.T.values * 1e6), vmin=0, vmax=10, cmap=my_cmap)\n",
    "plt.colorbar(cbar, pad=0.01, aspect=20)  # .set_ticks(np.arange(0,,1))\n",
    "ax.set_ylabel(r'$Diameter \\  (mm)$', fontsize='x-large')\n",
    "ax.set_xlabel('$Time \\  (UTC)$', fontsize='x-large')\n",
    "plt.title('$N(D), \\log_{10} (\\# \\ m^{-3} mm^{-1}) $', position=(0.8, 0.1), fontsize='x-large')\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "ax.set_yscale('log')\n",
    "title = f\"{key: %Y-%m-%d} UTC - {aircraft}\"\n",
    "fig.suptitle(title, fontsize=14, fontweight='bold', y=0.99)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991edc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = f\"{path_data}/zarr/combined_psd_test.zarr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b33d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = xr_merg.to_zarr(store=store, consolidated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da39982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = xr.open_zarr(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0542c577",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f28ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(params.index, params['lwc'])\n",
    "plt.title('LWC (g m-3)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22df4346",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(params.index, params['dm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e10119",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(params.index, params['nw'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dac88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "1e6/1e15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088789c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "1000 ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c3ad321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_pickle('/data/keeling/a/alfonso8/gpm/camp2ex/pkl/2DS10_Learjet.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "343930dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hvps = pd.read_pickle('/data/keeling/a/alfonso8/gpm/camp2ex/pkl/HVPS_Learjet.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "63195682",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26110/3527569539.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhvps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/camp2ex_proj/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/camp2ex_proj/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    358\u001b[0m     )\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/camp2ex_proj/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0mcons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"concat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_result_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/camp2ex_proj/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__finalize__\u001b[0;34m(self, other, method, **kwargs)\u001b[0m\n\u001b[1;32m   5547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"concat\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5548\u001b[0m             \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5549\u001b[0;31m             \u001b[0mcheck_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobjs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck_attrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5551\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/camp2ex_proj/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   5547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"concat\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5548\u001b[0m             \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5549\u001b[0;31m             \u001b[0mcheck_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobjs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck_attrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5551\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "pd.concat([ds, hvps], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:camp2ex_proj] *",
   "language": "python",
   "name": "conda-env-camp2ex_proj-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
